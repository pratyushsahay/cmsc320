---
title: "CMSC320 Final Project"
author: "Pratyush Sahay"
date: "May 17, 2018"
output: html_document
---

Introduction
Have you ever wondered which factors of a student's life and their individual engagement in class effect how well they perform? I will be using an educational dataset of students' academic performance, which was collected from a learning management system called Kalboard 360 (more information can be found here: http://test3.aimstyle.com/AboutUs.aspx), to answer this question. The steps required to answer this question include tidying the dataset, exploratory data analysis, hypothesis testing, modelling, and model selection.

I will be using R in RStudio to complete my analysis and modelling.
R download link: https://www.r-project.org/
RStudio download link: https://www.rstudio.com/products/rstudio/

This project requires the following libraries which can be downloaded in the RStudio IDE:
tidyverse
data.table
dplyr
ISLR
broom
ggplot2
tree
cvTools
nnet
caTools
randomForest
caret
e1071
Information about each of the packages can be found in the RStudio IDE help tab.

Finally, you can download the Students' Academic Performance Dataset from: https://www.kaggle.com/aljarah/xAPI-Edu-Data

1. Load and View Data
After downloading the dataset, we must load it into R as a dataframe that we can manipulate by performing various functions. We do so by using the read_csv() command and putting the results into the variable named "df". We must also load all of the libraries needed.
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
library(tidyverse)
library(data.table)
library(dplyr)
library(ISLR)
library(broom)
library(ggplot2)
library(tree)
library(cvTools)
library(nnet)
library(caTools)
library(randomForest)
library(caret)
library(e1071)
df <- read_csv("performance.csv")
```

We can take a peek at what the dataset looks like using the head() function. We see that the dataset has 17 columns. Each column represents a single student. Some of the columns include:
gender - Student's gender
raisedhands - How many times the student raises his/her hand in class
Class - Classification based on grade. Put into three numeric intervals (H = 90-100, M = 70-89, L = 0-69)
etc. 
In order to get an understanding of what each of the columns represent, I encourage you to go to https://www.kaggle.com/aljarah/xAPI-Edu-Data and scroll down to the "Attributes" section in the "Overview" tab. This section gives a thorough explanation of what each column represents.

```{r display}
head(df)
```

2. Tidying Data
Now that we know what our dataset looks like, we can begin cleaning it up so it is more accessible and easier to maneuver.
We'll start by checking to see if there are any data points that are missing from the dataset. We will sum all of the data points that were represented as "NA" (missing) in the dataframe.

```{r missingData}
sapply(df, function(x) sum(is.na(x)))

```
As we can see from the output, there are no missing data points! This is good news for us since we don't need to remove any observations or plug in "random" or averaged data into the missing datapoints.

Next, we will factor our categorical attributes, which are currently stored as characters. The reason for this will become clear later in the tutorial. For now, it would be beneficial to brush up on categorical versus numerical variables which you can do here: http://www.dummies.com/education/math/statistics/types-of-statistical-data-numerical-categorical-and-ordinal/

```{r factorData}
### Factor Columns
col_names <- c("gender","NationalITy","PlaceofBirth","StageID","SectionID","Topic","Semester","Relation","ParentAnsweringSurvey","ParentschoolSatisfaction","StudentAbsenceDays","Class")
df[col_names] <- lapply(df[col_names] , factor)
```

The next step is to rename the columns in the dataset so they are easier to access and understand. We can also remove column 14, ParentAnsweringSurvey, as it is not very relevant to our research question. 
```{r rename}
### Rename Columns
colnames(df)[2] <- "Nationality"
colnames(df)[5] <- "Year"
colnames(df)[7] <- "Subject"
colnames(df)[11] <- "Resource"
colnames(df)[15] <- "Satisfaction"
colnames(df)[17] <- "GradeRange"

### Remove Unimportant Columns
df <- df[,-14] 

```
This concludes the data tidying process. We were pretty lucky with this particular dataset, as it did not require much tidying. In actuality, many more problems are likely to arise, such as missing data points, unclean formatting, and just messy data. Many more tidying operations and processes can be found here: https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html

3. Exploratory Data Analysis
Now that our data is clean, we can start learning more about it by using exploratory data analysis, which is the intermediate step to performing statistical or machine learning processes. The overall goal of this step is to learn about the data through visuals and statistics so we can determine what exactly the data is "telling" us about student's academic performances.

The variable that measures how well a student is performing would be the GradeRange variable. We will start by analyzing how some of the other variables influence the grade a student receives, if at all. Below is a histogram of the grade a student received, categorized by the parent primarily responsible for the student (Relation variable). We will be using the ggplot function to do so. Read more about the ggplot2 package here: http://ggplot2.tidyverse.org/
```{r parent}
ggplot(data = df, aes(x = GradeRange, fill = Relation)) + geom_bar() +
    labs(x = "Grade Received Range", y = "Student Count")

```

The histogram gives us some interesting information. It seems that for this sample of data, students who are primarily taken care of by their mother tend to be in the high and medium grade range. Students who are primarily taken care of by their father tend to be in the lower and medium range. There is obviously some kind of correlation between grade and relation. We will keep this in mind going forward.

Next we'll look at a histogram of student's grades categorized by the number of days a student was absent. We do so using the same methods as the previous histogram. The results are as follows:
```{r absences}
ggplot(data = df, aes(x = GradeRange, fill = StudentAbsenceDays)) + geom_bar() +
    labs(x = "Grade Received Range", y = "Student Count")
```
Again, we see a clear correlation between the grade range and the number of days that student was absent. Essentially what we are trying to accomplish with these plots is develop a hypothesis that predicts which variables are the most significant in explaining the grade a student received. As of now we can only make an educated guess about which variables are significant, based on the data visualizations. Later on we will use concrete methods to do so.


We continue this process by creating a histogram of a student's grade categorized by gender.
```{r gender}
ggplot(data = df, aes(x = GradeRange, fill = gender)) + geom_bar() +
    labs(x = "Grade Received Range", y = "Student Count")
```
The interpretation of this histogram isn't as obvious as the previous ones but we can still learn some information from it. We see that many more female students are in the high and medium range than in the lower range. In contrast, we see that many more male students are in the lower and medium range than in the high grade range.

Next, we create a histogram of grade received categorized by their parent's satisfaction with the school.
```{r satisfaction}
ggplot(data = df, aes(x = GradeRange, fill = Satisfaction), title(main="Histogram of Grade Received by Relation")) + geom_bar() +
    labs(x = "Grade Received Range", y = "Student Count")

```
Again there is some correlation between the two variables.

Next we want to see the overall distribution of students in the different grade ranges. As we'd expect, most of the students fall in the 70-89 range while about the same number fall into the remaining ranges. We create this graph by first finding the sum of students in each range and creating a "slice" for each one.
```{r gradeDistribution}
numHigh <- sum(df$GradeRange == 'H')
numMedium <- sum(df$GradeRange == 'M')
numLow <- sum(df$GradeRange == 'L')
slices <- c(numHigh, numMedium, numLow) 
lbls <- c("90-100: ", "70-89:  ","0-69: ")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(slices,labels = lbls, col=rainbow(length(lbls)),
  	main="Pie Chart of All Grade Distributions")
```

We can do the same thing for just female students. We filter out only female students in the dataset by using the filter function and specifying the filter criteria. Then we create the graph using the same method as above. You can read more about the filter function here: https://www.rdocumentation.org/packages/dplyr/versions/0.7.3/topics/filter
```{r gradeDistribution2}
female <- df %>%
  filter(gender=="F")
numHigh <- sum(female$GradeRange == 'H')
numMedium <- sum(female$GradeRange == 'M')
numLow <- sum(female$GradeRange == 'L')
slices <- c(numHigh, numMedium, numLow) 
lbls <- c("90-100: ", "70-89: ","0-69: ")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(slices,labels = lbls, col=rainbow(length(lbls)),
  	main="Pie Chart of Female Grade Distributions")
```
This graph tells us that there are about the same number of female students in the high and medium grade ranges and a minority 14% in the low grade range. This confirms our data from the histogram.

We do the same for all male students and reach the same conclusion as from the histogram.

```{r gradeDistribution3}
male <- df %>%
  filter(gender=="M")
numHigh <- sum(male$GradeRange == 'H')
numMedium <- sum(male$GradeRange == 'M')
numLow <- sum(male$GradeRange == 'L')
slices <- c(numHigh, numMedium, numLow) 
lbls <- c("90-100: ", "70-89: ","0-69: ")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(slices,labels = lbls, col=rainbow(length(lbls)),
  	main="Pie Chart of Male Grade Distributions")
```

We will now look at a series of box-and-whisker and violin plots. These plots will help us visualize the overall distribution of our response variable, grade ranges, plotted against the numerical variables in our dataset.
The first plot we will look at is raisedhands versus GradeRange. We will still be using ggplot for these plots.
```{r boxplot1}
ggplot(df, aes(x = GradeRange, y = raisedhands)) + geom_violin()
ggplot(data = df, aes(x = GradeRange, y = raisedhands)) + geom_boxplot()
```
There are four major components of these two plots that can describe the distribution:
Shape
Center of Distribution
Spread
Outliers

Shape: We can see that the high and low grade ranges have long tails, indicating that there is some skew. The medium range is fairly balanced as should be expected.
Center of Distribution: The high grade range is centered around high values of number of times a student raises his or her hand. The opposite is true for the low grade range. This means the mean of the high grade range is high whereas the mean of the low grade range is low (in terms of number of times a students raises his/her hand).
Spread: All three ranges have a similar spread in terms of range. High and low ranges are obviously more concentrated in their perspective regions while medium is fairly evenly spread.
Outliers: There are some outliers in both the high and low ranges which cause the mean and spread of these ranges to change.

Overall from this type of analysis, it is apparent that raisedhands is correlated to the grade a student receives.

We can do the same type of analysis or the remaining numerical variables. We will plot Resources versus GradeRange.
```{r boxplot2}
ggplot(df, aes(x = GradeRange, y = Resource)) + geom_violin()
ggplot(data = df, aes(x = GradeRange, y = Resource)) + geom_boxplot()
```
We come to the same conclusion as we did for raisedhands versus GradeRange.

The next plot will be for AnnouncementsView versus GradeRange.
```{r boxplot3}
ggplot(df, aes(x = GradeRange, y = AnnouncementsView)) + geom_violin()
ggplot(data = df, aes(x = GradeRange, y = AnnouncementsView)) + geom_boxplot()
```
We see that this plot is different than the other two. The low grade range is still concentrated towards the bottom of the plot but the high grade range is no longer concentrated towards the top. This is telling us that the number of times a student checks a new announcements results in the same number of students in the high grade range. This suggests that this variable might not be significant in our model later.

Finally, we plot Discussion versus GradeRange.
```{r boxplot4}
ggplot(df, aes(x = GradeRange, y = Discussion)) + geom_violin()
ggplot(data = df, aes(x = GradeRange, y = Discussion)) + geom_boxplot()
```
From this plot we can see that there is no apparent correlation between Discussion and GradeRange as the distribution is relatively even compared to the previous plots.


For this dataset, the 2 most influential numeric predictors that seem to be correlated with a grade in the highest range seem to be raisedhands and VisitedResources. The important categorical predictors seem to be gender, 

Logistic Fit

```{r initialFit}
fit <- multinom(GradeRange ~ raisedhands + Discussion + AnnouncementsView + Resource + gender + Satisfaction + Relation + StudentAbsenceDays + Subject + Semester + Year + Nationality, data=df)

z <- summary(fit)$coefficients/summary(fit)$standard.errors
p <- (1 - pnorm(abs(z), 0, 1))*2

p
```

We can set up a hypothesis test to see which predictors are significant in explaining the response variable ie grades. The null hypothesis would be all b = 0 vs the alternative which would be at least 1 b not 0. If we test at a 5% significance level, the variables Discussion, AnnouncementsView, genderM, Subject, and year should be removed from the model since their p-values are greater than 0.05. However, looking at our plots from before, we may still want to keep at least the genderM variable. For this reason we will test the at a 8% level of significance. While there are some nationality dummy variables that are significant, there are a lot more that are not. For the sake of simplicity, I will remove nationality from the model. Now, we can remove all the predictors whose p-values are greater than 0.08.


https://www.analyticsvidhya.com/blog/2016/02/multinomial-ordinal-logistic-regression/
```{r refit}
fit2 <- multinom(GradeRange ~ raisedhands + Discussion + Resource + gender + Satisfaction + Relation + StudentAbsenceDays, data=df)

z <- summary(fit2)$coefficients/summary(fit2)$standard.errors
p <- (1 - pnorm(abs(z), 0, 1))*2

p
```

http://r-statistics.co/Multinomial-Regression-With-R.html
```{r logisticPrediction1}
test_indices <- sample(nrow(Auto), nrow(Auto)/2)
test_set <- df[test_indices,]
train_set <- df[-test_indices,]

logis_fit <- multinom(GradeRange ~ raisedhands + Discussion + Resource + gender + Satisfaction + Relation + StudentAbsenceDays, data=train_set)

logis_pred <- predict(logis_fit,test_set,type="probs")
predicted_class <- predict (logis_fit, test_set)

table(predicted_class, test_set$GradeRange)
mean(as.character(predicted_class) != as.character(test_set$GradeRange))
```

*** Decision Tree ***

```{r treePrediction1}
tree <- tree(GradeRange~raisedhands + Discussion + Resource + gender + Satisfaction + Relation + StudentAbsenceDays, data=df)
plot(tree)
text(tree, pretty=1, cex=0.7)
```

*** Cross Validation ***

```{r crossValidation}

fold_indices <- cvFolds(n=nrow(df), K=70)

error_rates <- sapply(1:10, function(fold_index) {
  test_indices <- which(fold_indices$which == fold_index)
  test_set <- df[test_indices,]
  train_set <- df[-test_indices,]
  
  logis_fit <- multinom(GradeRange ~ raisedhands + Discussion + Resource + gender + Satisfaction + Relation + StudentAbsenceDays, data=train_set)

  logis_pred <- predict(logis_fit,test_set,type="probs")
  predicted_class <- predict (logis_fit, test_set)

  table(predicted_class, test_set$GradeRange)
  logis_error <- mean(as.character(predicted_class) != as.character(test_set$GradeRange))
  
  tree_fit <- tree(GradeRange ~ raisedhands + +Discussion + Resource + gender + Satisfaction + Relation + StudentAbsenceDays, data=train_set)
  pruned_tree <- prune.tree(tree_fit, best=3)

  tree_pred <- predict(pruned_tree, newdata=test_set, type="class")
  tree_error <- mean(test_set$GradeRange != tree_pred)
  c(logis_error, tree_error)
  })
rownames(error_rates) <- c("logis", "tree")
error_rates <- as.data.frame(t(error_rates))

error_rates <- error_rates %>%
  mutate(fold=1:n()) %>%
  gather(method,error,-fold)

error_rates %>%
  head(50) %>%
  knitr::kable("html")
```

```{r randomForest}
set.seed(10)

test_indices <- sample(nrow(Auto), nrow(Auto)/2)
test_set <- df[test_indices,]
train_set <- df[-test_indices,]

rf <- randomForest(GradeRange~raisedhands + +Discussion + Resource + gender + Satisfaction + Relation + StudentAbsenceDays, data=train_set, ntree=5000, nodes = 20)

rf.predict <- predict(rf, test_set)
confusionMatrix(test_set$GradeRange, rf.predict)
```

